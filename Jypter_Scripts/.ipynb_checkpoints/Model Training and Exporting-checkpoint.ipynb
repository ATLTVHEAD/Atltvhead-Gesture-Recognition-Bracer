{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:36:55.143143Z",
     "start_time": "2020-07-05T01:36:55.138958Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime\n",
    "import re\n",
    "import os, os.path\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:36:55.995945Z",
     "start_time": "2020-07-05T01:36:55.992168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/data/Training_Data\n"
     ]
    }
   ],
   "source": [
    "cd ../Training_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:43.016444Z",
     "start_time": "2020-07-05T01:36:56.984189Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('processed_train_set.csv',converters={'acceleration': eval})\n",
    "test_set = pd.read_csv('processed_test_set.csv',converters={'acceleration': eval})\n",
    "val_set = pd.read_csv('processed_val_set.csv',converters={'acceleration': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:43.033315Z",
     "start_time": "2020-07-05T01:37:43.021214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/data/Model\n"
     ]
    }
   ],
   "source": [
    "cd ../Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:45.057761Z",
     "start_time": "2020-07-05T01:37:45.054105Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_model_size(model):\n",
    "    print(model.summary())\n",
    "    var_sizes = [\n",
    "      np.product(list(map(int, v.shape))) * v.dtype.size\n",
    "      for v in model.trainable_variables\n",
    "      ]\n",
    "    print(\"Model size:\", sum(var_sizes) / 1024, \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:48.924497Z",
     "start_time": "2020-07-05T01:37:47.960006Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = len(train_set['acceleration'][0])\n",
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Bidirectional(\n",
    "          tf.keras.layers.LSTM(22),\n",
    "          input_shape=(samples, 3)),  # output_shape=(batch, 44)\n",
    "      tf.keras.layers.Dense(4, activation=\"sigmoid\")  # (batch, 4)\n",
    "])\n",
    "\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (4, 3),padding=\"same\",activation=\"relu\",\n",
    "                           input_shape=(samples, 3, 1)),  # output_shape=(batch, 128, 3, 8)\n",
    "    tf.keras.layers.MaxPool2D((3, 3)),  # (batch, 42, 1, 8)\n",
    "    tf.keras.layers.Dropout(0.1),  # (batch, 42, 1, 8)\n",
    "    tf.keras.layers.Conv2D(16, (4, 1), padding=\"same\",activation=\"relu\"),  # (batch, 42, 1, 16)\n",
    "    tf.keras.layers.MaxPool2D((3, 1), padding=\"same\"),  # (batch, 14, 1, 16)\n",
    "    tf.keras.layers.Dropout(0.1),  # (batch, 14, 1, 16)\n",
    "    tf.keras.layers.Flatten(),  # (batch, 224)\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),  # (batch, 16)\n",
    "    tf.keras.layers.Dropout(0.1),  # (batch, 16)\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\")  # (batch, 4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:53.351788Z",
     "start_time": "2020-07-05T01:37:48.974014Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor_train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(train_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     train_set['gesture'].tolist()))\n",
    "\n",
    "tensor_test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(test_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     test_set['gesture'].tolist()))\n",
    "\n",
    "tensor_val_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(val_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     val_set['gesture'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:53.406551Z",
     "start_time": "2020-07-05T01:37:53.354701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 44)                4576      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 180       \n",
      "=================================================================\n",
      "Total params: 4,756\n",
      "Trainable params: 4,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model size: 18.578125 KB\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 760, 3, 8)         104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 253, 1, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 253, 1, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 253, 1, 16)        528       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 85, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1360)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                21776     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 22,476\n",
      "Trainable params: 22,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model size: 87.796875 KB\n"
     ]
    }
   ],
   "source": [
    "calculate_model_size(lstm_model)\n",
    "epochs_cnn = 20\n",
    "epochs_lstm = 10\n",
    "batch_size = 64\n",
    "lstm_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "calculate_model_size(cnn_model)\n",
    "cnn_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:53.422261Z",
     "start_time": "2020-07-05T01:37:53.408919Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor_train_set_lstm = tensor_train_set.batch(batch_size).repeat()\n",
    "tensor_val_set_lstm = tensor_val_set.batch(batch_size)\n",
    "tensor_test_set_lstm = tensor_test_set.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:12:05.050805Z",
     "start_time": "2020-07-05T01:37:54.581124Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 0.7699 - accuracy: 0.7028 - val_loss: 0.5558 - val_accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 201s 201ms/step - loss: 0.2992 - accuracy: 0.9013 - val_loss: 0.4191 - val_accuracy: 0.8529\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 201s 201ms/step - loss: 0.1656 - accuracy: 0.9475 - val_loss: 0.3408 - val_accuracy: 0.9118\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 200s 200ms/step - loss: 0.1474 - accuracy: 0.9527 - val_loss: 0.3416 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 0.1591 - accuracy: 0.9488 - val_loss: 0.3129 - val_accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 201s 201ms/step - loss: 0.1168 - accuracy: 0.9632 - val_loss: 0.3937 - val_accuracy: 0.9412\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 201s 201ms/step - loss: 0.1014 - accuracy: 0.9678 - val_loss: 0.3301 - val_accuracy: 0.9412\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 0.0817 - accuracy: 0.9750 - val_loss: 0.4605 - val_accuracy: 0.8971\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 207s 207ms/step - loss: 0.0643 - accuracy: 0.9777 - val_loss: 0.4785 - val_accuracy: 0.8676\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 226s 226ms/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 0.5531 - val_accuracy: 0.8382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb19114e950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(\n",
    "    tensor_train_set_lstm,\n",
    "    epochs=epochs_lstm,\n",
    "    validation_data=tensor_val_set_lstm,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=int((len(val_set) - 1) / batch_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:13:50.857238Z",
     "start_time": "2020-07-05T02:13:50.219030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 909us/step - loss: 0.0361 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss_lstm, acc_lstm = lstm_model.evaluate(tensor_test_set_lstm)\n",
    "pred_lstm = np.argmax(lstm_model.predict(tensor_test_set_lstm), axis=1)\n",
    "confusion_lstm = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_set['gesture'].to_numpy()),\n",
    "    predictions=tf.constant(pred_lstm),\n",
    "    num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:13:52.509531Z",
     "start_time": "2020-07-05T02:13:52.494055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[14  0  0  0]\n",
      " [ 0 10  0  0]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0  0  8]], shape=(4, 4), dtype=int32)\n",
      "Loss 0.03605746477842331, Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "print(confusion_lstm)\n",
    "print(\"Loss {}, Accuracy {}\".format(loss_lstm, acc_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:14:11.979868Z",
     "start_time": "2020-07-05T02:14:04.305985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120932"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)\n",
    "lstm_tflite_model = converter.convert()\n",
    "\n",
    "open(\"lstm_model.tflite\", \"wb\").write(lstm_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:15:22.785851Z",
     "start_time": "2020-07-05T02:15:17.931532Z"
    }
   },
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2020-07-05 02:15:22.259937: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\n2020-07-05 02:15:22.260052: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\n2020-07-05 02:15:22.312754: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2020-07-05 02:15:22.338157: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2208005000 Hz\n2020-07-05 02:15:22.339093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efb84000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-07-05 02:15:22.339154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-07-05 02:15:22.343180: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2020-07-05 02:15:22.343237: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n2020-07-05 02:15:22.343259: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f1f339396102): /proc/driver/nvidia/version does not exist\n2020-07-05 02:15:22.389845: E tensorflow/lite/tools/optimize/quantize_weights.cc:351] Quantize weights tool only supports tflite models with one subgraph.\nTraceback (most recent call last):\n  File \"/opt/conda/bin/toco_from_protos\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\n    enable_mlir_converter)\nException: Quantize weights transformation failed.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e038ff3c2b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZE_FOR_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlstm_opt_tflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstm_model_quantized.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_opt_tflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    497\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2020-07-05 02:15:22.259937: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\n2020-07-05 02:15:22.260052: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\n2020-07-05 02:15:22.312754: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2020-07-05 02:15:22.338157: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2208005000 Hz\n2020-07-05 02:15:22.339093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efb84000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-07-05 02:15:22.339154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-07-05 02:15:22.343180: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2020-07-05 02:15:22.343237: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n2020-07-05 02:15:22.343259: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f1f339396102): /proc/driver/nvidia/version does not exist\n2020-07-05 02:15:22.389845: E tensorflow/lite/tools/optimize/quantize_weights.cc:351] Quantize weights tool only supports tflite models with one subgraph.\nTraceback (most recent call last):\n  File \"/opt/conda/bin/toco_from_protos\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\n    enable_mlir_converter)\nException: Quantize weights transformation failed.\n\n\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "lstm_opt_tflite_model = converter.convert()\n",
    "# Save the model to disk\n",
    "open(\"lstm_model_quantized.tflite\", \"wb\").write(lstm_opt_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:15:32.342762Z",
     "start_time": "2020-07-05T02:15:32.310067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic model is 120932 bytes\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lstm_model_quantized.tflite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7f29bd8499a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbasic_model_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstm_model.tflite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Basic model is %d bytes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbasic_model_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mquantized_model_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstm_model_quantized.tflite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantized model is %d bytes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mquantized_model_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_model_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mquantized_model_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lstm_model_quantized.tflite'"
     ]
    }
   ],
   "source": [
    "basic_model_size = os.path.getsize(\"lstm_model.tflite\")\n",
    "print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "quantized_model_size = os.path.getsize(\"lstm_model_quantized.tflite\")\n",
    "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "difference = basic_model_size - quantized_model_size\n",
    "print(\"Difference is %d bytes\" % difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_function(data, label):\n",
    "    reshaped_data = tf.reshape(data, [-1, 3, 1])\n",
    "    return reshaped_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('processed_train_set.csv',converters={'acceleration': eval})\n",
    "test_set = pd.read_csv('processed_test_set.csv',converters={'acceleration': eval})\n",
    "val_set = pd.read_csv('processed_val_set.csv',converters={'acceleration': eval})\n",
    "\n",
    "tensor_train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(train_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     train_set['gesture'].tolist()))\n",
    "\n",
    "tensor_test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(test_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     test_set['gesture'].tolist()))\n",
    "\n",
    "tensor_val_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(val_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     val_set['gesture'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train_set_cnn = tensor_train_set.map(reshape_function)\n",
    "tensor_test_set_cnn = tensor_test_set.map(reshape_function)\n",
    "tensor_val_set_cnn = tensor_val_set.map(reshape_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train_set_cnn = tensor_train_set_cnn.batch(batch_size).repeat()\n",
    "tensor_test_set_cnn = tensor_test_set_cnn.batch(batch_size)\n",
    "tensor_val_set_cnn = tensor_val_set_cnn.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_model.fit(\n",
    "    tensor_train_set_cnn,\n",
    "    epochs=epochs_cnn,\n",
    "    validation_data=tensor_val_set_cnn,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=int((len(val_set) - 1) / batch_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_cnn, acc_cnn = cnn_model.evaluate(tensor_test_set_cnn)\n",
    "pred_cnn = np.argmax(cnn_model.predict(tensor_test_set_cnn), axis=1)\n",
    "confusion_cnn = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_set['gesture'].to_numpy()),\n",
    "    predictions=tf.constant(pred_cnn),\n",
    "    num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(confusion_cnn)\n",
    "print(\"Loss {}, Accuracy {}\".format(loss_cnn, acc_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
    "cnn_tflite_model = converter.convert()\n",
    "\n",
    " open(\"cnn_model.tflite\", \"wb\").write(cnn_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "cnn_opt_tflite_model = converter.convert()\n",
    "# Save the model to disk\n",
    "open(\"cnn_model_quantized.tflite\", \"wb\").write(cnn_opt_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_model_size = os.path.getsize(\"cnn_model.tflite\")\n",
    "print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "quantized_model_size = os.path.getsize(\"cnn_model_quantized.tflite\")\n",
    "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "difference = basic_model_size - quantized_model_size\n",
    "print(\"Difference is %d bytes\" % difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:27:51.433418Z",
     "start_time": "2020-07-05T01:27:49.772098Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "/bin/sh: 1: cannot create /cnn_opt_model.cc: Permission denied\n",
      "cat: /cnn_opt_model.cc: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get -qq install xxd\n",
    "# Save the file as a C source file\n",
    "!xxd -i cnn_model_quantized.tflite > /cnn_opt_model.cc\n",
    "# Print the source file\n",
    "!cat /cnn_opt_model.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:36:55.143143Z",
     "start_time": "2020-07-05T01:36:55.138958Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime\n",
    "import re\n",
    "import os, os.path\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:36:55.995945Z",
     "start_time": "2020-07-05T01:36:55.992168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\nated\\Documents\\Python Scripts\\Atltvhead-Gesture-Recognition-Bracer\\Training_Data\n"
    }
   ],
   "source": [
    "cd ../Training_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:43.016444Z",
     "start_time": "2020-07-05T01:36:56.984189Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('processed_train_set.csv',converters={'acceleration': eval})\n",
    "test_set = pd.read_csv('processed_test_set.csv',converters={'acceleration': eval})\n",
    "val_set = pd.read_csv('processed_val_set.csv',converters={'acceleration': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:43.033315Z",
     "start_time": "2020-07-05T01:37:43.021214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\nated\\Documents\\Python Scripts\\Atltvhead-Gesture-Recognition-Bracer\\Model\n"
    }
   ],
   "source": [
    "cd ../Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:45.057761Z",
     "start_time": "2020-07-05T01:37:45.054105Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_model_size(model):\n",
    "    print(model.summary())\n",
    "    var_sizes = [\n",
    "      np.product(list(map(int, v.shape))) * v.dtype.size\n",
    "      for v in model.trainable_variables\n",
    "      ]\n",
    "    print(\"Model size:\", sum(var_sizes) / 1024, \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:48.924497Z",
     "start_time": "2020-07-05T01:37:47.960006Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = len(train_set['acceleration'][0])\n",
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Bidirectional(\n",
    "          tf.keras.layers.LSTM(22),\n",
    "          input_shape=(samples, 3)),  # output_shape=(batch, 44)\n",
    "      tf.keras.layers.Dense(4, activation=\"sigmoid\")  # (batch, 4)\n",
    "])\n",
    "\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (4, 3),padding=\"same\",activation=\"relu\",\n",
    "                           input_shape=(samples, 3, 1)),  # output_shape=(batch, 128, 3, 8)\n",
    "    tf.keras.layers.MaxPool2D((3, 3)),  # (batch, 42, 1, 8)\n",
    "    tf.keras.layers.Dropout(0.1),  # (batch, 42, 1, 8)\n",
    "    tf.keras.layers.Conv2D(16, (4, 1), padding=\"same\",activation=\"relu\"),  # (batch, 42, 1, 16)\n",
    "    tf.keras.layers.MaxPool2D((3, 1), padding=\"same\"),  # (batch, 14, 1, 16)\n",
    "    tf.keras.layers.Dropout(0.1),  # (batch, 14, 1, 16)\n",
    "    tf.keras.layers.Flatten(),  # (batch, 224)\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),  # (batch, 16)\n",
    "    tf.keras.layers.Dropout(0.1),  # (batch, 16)\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\")  # (batch, 4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:53.351788Z",
     "start_time": "2020-07-05T01:37:48.974014Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor_train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(train_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     train_set['gesture'].tolist()))\n",
    "\n",
    "tensor_test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(test_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     test_set['gesture'].tolist()))\n",
    "\n",
    "tensor_val_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(val_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     val_set['gesture'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:53.406551Z",
     "start_time": "2020-07-05T01:37:53.354701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbidirectional (Bidirectional (None, 44)                4576      \n_________________________________________________________________\ndense (Dense)                (None, 4)                 180       \n=================================================================\nTotal params: 4,756\nTrainable params: 4,756\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel size: 18.578125 KB\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 760, 3, 8)         104       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 253, 1, 8)         0         \n_________________________________________________________________\ndropout (Dropout)            (None, 253, 1, 8)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 253, 1, 16)        528       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 85, 1, 16)         0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 85, 1, 16)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1360)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                21776     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 16)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 68        \n=================================================================\nTotal params: 22,476\nTrainable params: 22,476\nNon-trainable params: 0\n_________________________________________________________________\nNone\nModel size: 87.796875 KB\n"
    }
   ],
   "source": [
    "calculate_model_size(lstm_model)\n",
    "epochs_cnn = 20\n",
    "epochs_lstm = 10\n",
    "batch_size = 64\n",
    "lstm_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "calculate_model_size(cnn_model)\n",
    "cnn_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:37:53.422261Z",
     "start_time": "2020-07-05T01:37:53.408919Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor_train_set_lstm = tensor_train_set.batch(batch_size).repeat()\n",
    "tensor_val_set_lstm = tensor_val_set.batch(batch_size)\n",
    "tensor_test_set_lstm = tensor_test_set.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:12:05.050805Z",
     "start_time": "2020-07-05T01:37:54.581124Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model.fit(\n",
    "    tensor_train_set_lstm,\n",
    "    epochs=epochs_lstm,\n",
    "    validation_data=tensor_val_set_lstm,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=int((len(val_set) - 1) / batch_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:13:50.857238Z",
     "start_time": "2020-07-05T02:13:50.219030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_lstm, acc_lstm = lstm_model.evaluate(tensor_test_set_lstm)\n",
    "pred_lstm = np.argmax(lstm_model.predict(tensor_test_set_lstm), axis=1)\n",
    "confusion_lstm = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_set['gesture'].to_numpy()),\n",
    "    predictions=tf.constant(pred_lstm),\n",
    "    num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:13:52.509531Z",
     "start_time": "2020-07-05T02:13:52.494055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(confusion_lstm)\n",
    "print(\"Loss {}, Accuracy {}\".format(loss_lstm, acc_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:14:11.979868Z",
     "start_time": "2020-07-05T02:14:04.305985Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)\n",
    "lstm_tflite_model = converter.convert()\n",
    "\n",
    "open(\"lstm_model.tflite\", \"wb\").write(lstm_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:15:22.785851Z",
     "start_time": "2020-07-05T02:15:17.931532Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)\n",
    "converter.experimental_new_converter = True\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "lstm_opt_tflite_model = converter.convert()\n",
    "# Save the model to disk\n",
    "open(\"lstm_model_quantized.tflite\", \"wb\").write(lstm_opt_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T02:15:32.342762Z",
     "start_time": "2020-07-05T02:15:32.310067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_model_size = os.path.getsize(\"lstm_model.tflite\")\n",
    "print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "quantized_model_size = os.path.getsize(\"lstm_model_quantized.tflite\")\n",
    "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "difference = basic_model_size - quantized_model_size\n",
    "print(\"Difference is %d bytes\" % difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_function(data, label):\n",
    "    reshaped_data = tf.reshape(data, [-1, 3, 1])\n",
    "    return reshaped_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('processed_train_set.csv',converters={'acceleration': eval})\n",
    "test_set = pd.read_csv('processed_test_set.csv',converters={'acceleration': eval})\n",
    "val_set = pd.read_csv('processed_val_set.csv',converters={'acceleration': eval})\n",
    "\n",
    "tensor_train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(train_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     train_set['gesture'].tolist()))\n",
    "\n",
    "tensor_test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(test_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     test_set['gesture'].tolist()))\n",
    "\n",
    "tensor_val_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.array(val_set['acceleration'].tolist(),dtype=np.float64),\n",
    "     val_set['gesture'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train_set_cnn = tensor_train_set.map(reshape_function)\n",
    "tensor_test_set_cnn = tensor_test_set.map(reshape_function)\n",
    "tensor_val_set_cnn = tensor_val_set.map(reshape_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train_set_cnn = tensor_train_set_cnn.batch(batch_size).repeat()\n",
    "tensor_test_set_cnn = tensor_test_set_cnn.batch(batch_size)\n",
    "tensor_val_set_cnn = tensor_val_set_cnn.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_model.fit(\n",
    "    tensor_train_set_cnn,\n",
    "    epochs=epochs_cnn,\n",
    "    validation_data=tensor_val_set_cnn,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=int((len(val_set) - 1) / batch_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_cnn, acc_cnn = cnn_model.evaluate(tensor_test_set_cnn)\n",
    "pred_cnn = np.argmax(cnn_model.predict(tensor_test_set_cnn), axis=1)\n",
    "confusion_cnn = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_set['gesture'].to_numpy()),\n",
    "    predictions=tf.constant(pred_cnn),\n",
    "    num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(confusion_cnn)\n",
    "print(\"Loss {}, Accuracy {}\".format(loss_cnn, acc_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
    "cnn_tflite_model = converter.convert()\n",
    "\n",
    " open(\"cnn_model.tflite\", \"wb\").write(cnn_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "cnn_opt_tflite_model = converter.convert()\n",
    "# Save the model to disk\n",
    "open(\"cnn_model_quantized.tflite\", \"wb\").write(cnn_opt_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_model_size = os.path.getsize(\"cnn_model.tflite\")\n",
    "print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "quantized_model_size = os.path.getsize(\"cnn_model_quantized.tflite\")\n",
    "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "difference = basic_model_size - quantized_model_size\n",
    "print(\"Difference is %d bytes\" % difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T01:27:51.433418Z",
     "start_time": "2020-07-05T01:27:49.772098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "#!apt-get -qq install xxd\n",
    "# Save the file as a C source file\n",
    "#!xxd -i cnn_model_quantized.tflite > cnn_opt_model.cc\n",
    "# Print the source file\n",
    "#!cat /cnn_opt_model.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1593920406992"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}